# Threat Intelligence Report: LangChain Serialization Vulnerability
**Date:** 2025-12-28
**CVE ID:** CVE-2025-68664
**Severity:** Critical (CVSS 9.3)
**Author:** Nedheesh Hasija

---

## 1. Executive Summary
A critical security flaw has been discovered in **LangChain Core**, a library widely used for building AI and LLM applications. This vulnerability allows remote attackers to steal sensitive secrets (such as API keys) and influence model responses via "Prompt Injection."

**Status:** Patched.
**Recommendation:** Immediate update to patched versions (0.3.81 or 1.2.5) is required to prevent data exfiltration.

## 2. Technical Analysis
**The Mechanism:**
The vulnerability is a **Serialization Injection** flaw located in LangChain's `dumps()` and `dumpd()` functions.
* These functions fail to properly escape dictionaries containing the specific key `"lc"`.
* The `"lc"` key is used internally by LangChain to mark serialized objects.
* When user-controlled data (like a prompt) contains this key structure, the system mistakenly treats it as a legitimate LangChain object during deserialization.

**The Risk:**
An attacker can force the application to instantiate unsafe, arbitrary objects. This creates a vector for **Remote Code Execution (RCE)** or the extraction of environment variables (secrets) simply by processing a malicious prompt.

## 3. Impact & Action Plan
**Impact:**
* **Secret Extraction:** Attackers can read environment variables (AWS keys, OpenAI keys).
* **Code Execution:** Potential for arbitrary code execution via Jinja2 templates.

**Remediation:**
1.  **Audit:** Scan the codebase for `langchain-core` versions `< 0.3.81`.
2.  **Patch:** Update `langchain-core` immediately:
    * For 1.x users: Update to `1.2.5`.
    * For 0.3.x users: Update to `0.3.81`.